
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Twitter Sentiment Model - Jupyter Notebook\n",
    "This notebook loads and cleans Twitter data, trains a sentiment classifier, and evaluates it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install emoji wordcloud scikit-learn nltk seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload training data\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "df_train = pd.read_csv('twitter_training.csv', header=None)\n",
    "df_train.columns = ['id', 'entity', 'sentiment', 'text']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean tweet text\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r"http\\S+|www\\S+|https\\S+", '', text)\n",
    "    text = re.sub(r"@\\w+|\\#", '', text)\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    text = re.sub(r"[^a-zA-Z\\s]", '', text)\n",
    "    tokens = text.split()\n",
    "    filtered = [w for w in tokens if w not in stop_words]\n",
    "    return " ".join(filtered)\n",
    "\n",
    "df_train['cleaned_text'] = df_train['text'].apply(clean_text)\n",
    "df_train[['text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud per sentiment\n",
    "for sentiment in df_train['sentiment'].unique():\n",
    "    text = " ".join(df_train[df_train['sentiment'] == sentiment]['cleaned_text'])\n",
    "    wc = WordCloud(width=800, height=400).generate(text)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f"WordCloud - {sentiment}")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train TF-IDF + Naive Bayes model\n",
    "X = df_train['cleaned_text']\n",
    "y = df_train['sentiment']\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload validation file\n",
    "uploaded = files.upload()\n",
    "df_val = pd.read_csv('twitter_validation.csv', header=None)\n",
    "df_val.columns = ['id', 'entity', 'sentiment', 'text']\n",
    "df_val['cleaned_text'] = df_val['text'].apply(clean_text)\n",
    "X_val = vectorizer.transform(df_val['cleaned_text'])\n",
    "y_val = df_val['sentiment']\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred, labels=model.classes_)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.xlabel("Predicted")\n",
    "plt.ylabel("Actual")\n",
    "plt.title("Confusion Matrix")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
